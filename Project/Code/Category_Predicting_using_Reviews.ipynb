{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728df65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import html\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from nltk.corpus import wordnet\n",
    "from typing import List\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import spacy\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint\n",
    "from numpy import array, argmax, asarray, zeros\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import SimpleRNN, LSTM\n",
    "from keras.layers import Flatten, Masking\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b245ee98",
   "metadata": {},
   "source": [
    "## Text Preprocessing - Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded23d13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podcast_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>itunes_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>itunes_url</th>\n",
       "      <th>podcast_title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b313ef8ef0d5b64290d3036ff1bbf2d2</td>\n",
       "      <td>감성 라디오 음악도시</td>\n",
       "      <td>미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...</td>\n",
       "      <td>5</td>\n",
       "      <td>664CCA7142E9AE8</td>\n",
       "      <td>2011-09-14T13:25:46-07:00</td>\n",
       "      <td>442838670</td>\n",
       "      <td>fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/fm-%EC%9...</td>\n",
       "      <td>FM 음악도시(종영)</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abfb842993be20d21bfae7103addc5e9</td>\n",
       "      <td>They’ve really cut back on the content this se...</td>\n",
       "      <td>Last season there was a new pod every 3-4 days...</td>\n",
       "      <td>1</td>\n",
       "      <td>AD790CE113DCBC1</td>\n",
       "      <td>2018-04-11T13:46:47-07:00</td>\n",
       "      <td>1015394113</td>\n",
       "      <td>the-good-phight-for-philadelphia-phillies-fans</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/the-good...</td>\n",
       "      <td>The Good Phight: for Philadelphia Phillies fans</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         podcast_id  \\\n",
       "0  b313ef8ef0d5b64290d3036ff1bbf2d2   \n",
       "1  abfb842993be20d21bfae7103addc5e9   \n",
       "\n",
       "                                               title  \\\n",
       "0                                        감성 라디오 음악도시   \n",
       "1  They’ve really cut back on the content this se...   \n",
       "\n",
       "                                             content  rating        author_id  \\\n",
       "0  미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...       5  664CCA7142E9AE8   \n",
       "1  Last season there was a new pod every 3-4 days...       1  AD790CE113DCBC1   \n",
       "\n",
       "                  created_at   itunes_id  \\\n",
       "0  2011-09-14T13:25:46-07:00   442838670   \n",
       "1  2018-04-11T13:46:47-07:00  1015394113   \n",
       "\n",
       "                                                slug  \\\n",
       "0  fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...   \n",
       "1     the-good-phight-for-philadelphia-phillies-fans   \n",
       "\n",
       "                                          itunes_url  \\\n",
       "0  https://podcasts.apple.com/us/podcast/fm-%EC%9...   \n",
       "1  https://podcasts.apple.com/us/podcast/the-good...   \n",
       "\n",
       "                                     podcast_title category  \n",
       "0                                      FM 음악도시(종영)    music  \n",
       "1  The Good Phight: for Philadelphia Phillies fans   sports  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv('podcast_sample.csv', lineterminator='\\n', index_col = 0)\n",
    "sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7e09820",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Perform lemmatization\n",
    "## Reference: https://gist.github.com/gaurav5430/9fce93759eb2f6b1697883c3782f30de#file-nltk-lemmatize-sentences-py\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "def lem(line):\n",
    "    word_tokens = nltk.word_tokenize(line)\n",
    "    word_tokens = [lemmatize_sentence(t) for t in word_tokens]\n",
    "    cleaned_review = \" \".join(word_tokens)\n",
    "        \n",
    "    return cleaned_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3402472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podcast_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>itunes_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>itunes_url</th>\n",
       "      <th>podcast_title</th>\n",
       "      <th>category</th>\n",
       "      <th>reviews_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b313ef8ef0d5b64290d3036ff1bbf2d2</td>\n",
       "      <td>감성 라디오 음악도시</td>\n",
       "      <td>미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...</td>\n",
       "      <td>5</td>\n",
       "      <td>664CCA7142E9AE8</td>\n",
       "      <td>2011-09-14T13:25:46-07:00</td>\n",
       "      <td>442838670</td>\n",
       "      <td>fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/fm-%EC%9...</td>\n",
       "      <td>FM 음악도시(종영)</td>\n",
       "      <td>music</td>\n",
       "      <td>감성 라디오 음악도시 미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abfb842993be20d21bfae7103addc5e9</td>\n",
       "      <td>They’ve really cut back on the content this se...</td>\n",
       "      <td>Last season there was a new pod every 3-4 days...</td>\n",
       "      <td>1</td>\n",
       "      <td>AD790CE113DCBC1</td>\n",
       "      <td>2018-04-11T13:46:47-07:00</td>\n",
       "      <td>1015394113</td>\n",
       "      <td>the-good-phight-for-philadelphia-phillies-fans</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/the-good...</td>\n",
       "      <td>The Good Phight: for Philadelphia Phillies fans</td>\n",
       "      <td>sports</td>\n",
       "      <td>they’ve really cut back on the content this se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         podcast_id  \\\n",
       "0  b313ef8ef0d5b64290d3036ff1bbf2d2   \n",
       "1  abfb842993be20d21bfae7103addc5e9   \n",
       "\n",
       "                                               title  \\\n",
       "0                                        감성 라디오 음악도시   \n",
       "1  They’ve really cut back on the content this se...   \n",
       "\n",
       "                                             content  rating        author_id  \\\n",
       "0  미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...       5  664CCA7142E9AE8   \n",
       "1  Last season there was a new pod every 3-4 days...       1  AD790CE113DCBC1   \n",
       "\n",
       "                  created_at   itunes_id  \\\n",
       "0  2011-09-14T13:25:46-07:00   442838670   \n",
       "1  2018-04-11T13:46:47-07:00  1015394113   \n",
       "\n",
       "                                                slug  \\\n",
       "0  fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...   \n",
       "1     the-good-phight-for-philadelphia-phillies-fans   \n",
       "\n",
       "                                          itunes_url  \\\n",
       "0  https://podcasts.apple.com/us/podcast/fm-%EC%9...   \n",
       "1  https://podcasts.apple.com/us/podcast/the-good...   \n",
       "\n",
       "                                     podcast_title category  \\\n",
       "0                                      FM 음악도시(종영)    music   \n",
       "1  The Good Phight: for Philadelphia Phillies fans   sports   \n",
       "\n",
       "                                       reviews_title  \n",
       "0  감성 라디오 음악도시 미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀...  \n",
       "1  they’ve really cut back on the content this se...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat review title and review content to get more information later\n",
    "sample['reviews_title'] = sample['title'] + ' ' + sample['content']\n",
    "sample['reviews_title'] = sample['reviews_title'].astype(str)\n",
    "sample['reviews_title'] = sample['reviews_title'].apply(lambda x: x.lower())\n",
    "sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14bacecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podcast_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>itunes_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>itunes_url</th>\n",
       "      <th>podcast_title</th>\n",
       "      <th>category</th>\n",
       "      <th>reviews_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b313ef8ef0d5b64290d3036ff1bbf2d2</td>\n",
       "      <td>감성 라디오 음악도시</td>\n",
       "      <td>미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...</td>\n",
       "      <td>5</td>\n",
       "      <td>664CCA7142E9AE8</td>\n",
       "      <td>2011-09-14T13:25:46-07:00</td>\n",
       "      <td>442838670</td>\n",
       "      <td>fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/fm-%EC%9...</td>\n",
       "      <td>FM 음악도시(종영)</td>\n",
       "      <td>music</td>\n",
       "      <td>감성 라디오 음악도시 미국 서부에 있는 유학생이에요 . 성시경씨 제대 후 라디오 복...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abfb842993be20d21bfae7103addc5e9</td>\n",
       "      <td>They’ve really cut back on the content this se...</td>\n",
       "      <td>Last season there was a new pod every 3-4 days...</td>\n",
       "      <td>1</td>\n",
       "      <td>AD790CE113DCBC1</td>\n",
       "      <td>2018-04-11T13:46:47-07:00</td>\n",
       "      <td>1015394113</td>\n",
       "      <td>the-good-phight-for-philadelphia-phillies-fans</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/the-good...</td>\n",
       "      <td>The Good Phight: for Philadelphia Phillies fans</td>\n",
       "      <td>sports</td>\n",
       "      <td>they ’ ve really cut back on the content this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ebdf879a424547d01862a9bbba18a0f3</td>\n",
       "      <td>Good info. source...</td>\n",
       "      <td>Bob brings a lot of knowledge to any firearm d...</td>\n",
       "      <td>4</td>\n",
       "      <td>E223A4B2642C970</td>\n",
       "      <td>2010-01-19T08:11:43-07:00</td>\n",
       "      <td>333180229</td>\n",
       "      <td>handgun-world-podcast</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/handgun-...</td>\n",
       "      <td>Handgun World Podcast</td>\n",
       "      <td>news</td>\n",
       "      <td>good info . source ... bob brings a lot of kno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ab2fdb7db023b223d870487165d11ff3</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>They have lost much of thier credibility by de...</td>\n",
       "      <td>3</td>\n",
       "      <td>E1E7DBE750D119E</td>\n",
       "      <td>2021-01-28T12:21:49-07:00</td>\n",
       "      <td>971901464</td>\n",
       "      <td>wsj-opinion-potomac-watch</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/wsj-opin...</td>\n",
       "      <td>WSJ Opinion: Potomac Watch</td>\n",
       "      <td>news</td>\n",
       "      <td>mixed they have lose much of thier credibility...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ca601bd1524322d0527b16adf2738ff3</td>\n",
       "      <td>Try it now!</td>\n",
       "      <td>Even better than I expected. I was interested ...</td>\n",
       "      <td>5</td>\n",
       "      <td>D7CA4858AFA2CFC</td>\n",
       "      <td>2017-08-24T10:55:20-07:00</td>\n",
       "      <td>1257821731</td>\n",
       "      <td>conversations-with-people-who-hate-me</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/conversa...</td>\n",
       "      <td>Conversations with People Who Hate Me</td>\n",
       "      <td>society</td>\n",
       "      <td>try it now ! even well than i expect . i be in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         podcast_id  \\\n",
       "0  b313ef8ef0d5b64290d3036ff1bbf2d2   \n",
       "1  abfb842993be20d21bfae7103addc5e9   \n",
       "2  ebdf879a424547d01862a9bbba18a0f3   \n",
       "3  ab2fdb7db023b223d870487165d11ff3   \n",
       "4  ca601bd1524322d0527b16adf2738ff3   \n",
       "\n",
       "                                               title  \\\n",
       "0                                        감성 라디오 음악도시   \n",
       "1  They’ve really cut back on the content this se...   \n",
       "2                               Good info. source...   \n",
       "3                                              Mixed   \n",
       "4                                        Try it now!   \n",
       "\n",
       "                                             content  rating        author_id  \\\n",
       "0  미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...       5  664CCA7142E9AE8   \n",
       "1  Last season there was a new pod every 3-4 days...       1  AD790CE113DCBC1   \n",
       "2  Bob brings a lot of knowledge to any firearm d...       4  E223A4B2642C970   \n",
       "3  They have lost much of thier credibility by de...       3  E1E7DBE750D119E   \n",
       "4  Even better than I expected. I was interested ...       5  D7CA4858AFA2CFC   \n",
       "\n",
       "                  created_at   itunes_id  \\\n",
       "0  2011-09-14T13:25:46-07:00   442838670   \n",
       "1  2018-04-11T13:46:47-07:00  1015394113   \n",
       "2  2010-01-19T08:11:43-07:00   333180229   \n",
       "3  2021-01-28T12:21:49-07:00   971901464   \n",
       "4  2017-08-24T10:55:20-07:00  1257821731   \n",
       "\n",
       "                                                slug  \\\n",
       "0  fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...   \n",
       "1     the-good-phight-for-philadelphia-phillies-fans   \n",
       "2                              handgun-world-podcast   \n",
       "3                          wsj-opinion-potomac-watch   \n",
       "4              conversations-with-people-who-hate-me   \n",
       "\n",
       "                                          itunes_url  \\\n",
       "0  https://podcasts.apple.com/us/podcast/fm-%EC%9...   \n",
       "1  https://podcasts.apple.com/us/podcast/the-good...   \n",
       "2  https://podcasts.apple.com/us/podcast/handgun-...   \n",
       "3  https://podcasts.apple.com/us/podcast/wsj-opin...   \n",
       "4  https://podcasts.apple.com/us/podcast/conversa...   \n",
       "\n",
       "                                     podcast_title category  \\\n",
       "0                                      FM 음악도시(종영)    music   \n",
       "1  The Good Phight: for Philadelphia Phillies fans   sports   \n",
       "2                            Handgun World Podcast     news   \n",
       "3                       WSJ Opinion: Potomac Watch     news   \n",
       "4            Conversations with People Who Hate Me  society   \n",
       "\n",
       "                                       reviews_title  \n",
       "0  감성 라디오 음악도시 미국 서부에 있는 유학생이에요 . 성시경씨 제대 후 라디오 복...  \n",
       "1  they ’ ve really cut back on the content this ...  \n",
       "2  good info . source ... bob brings a lot of kno...  \n",
       "3  mixed they have lose much of thier credibility...  \n",
       "4  try it now ! even well than i expect . i be in...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['reviews_title'] = sample['reviews_title'].apply(lambda x: lem(x))\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59f4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.to_csv('df_lem.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91809a9d",
   "metadata": {},
   "source": [
    "## Read data after lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bab695db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podcast_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>itunes_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>itunes_url</th>\n",
       "      <th>podcast_title</th>\n",
       "      <th>category</th>\n",
       "      <th>reviews_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b313ef8ef0d5b64290d3036ff1bbf2d2</td>\n",
       "      <td>감성 라디오 음악도시</td>\n",
       "      <td>미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...</td>\n",
       "      <td>5</td>\n",
       "      <td>664CCA7142E9AE8</td>\n",
       "      <td>2011-09-14T13:25:46-07:00</td>\n",
       "      <td>442838670</td>\n",
       "      <td>fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/fm-%EC%9...</td>\n",
       "      <td>FM 음악도시(종영)</td>\n",
       "      <td>music</td>\n",
       "      <td>감성 라디오 음악도시 미국 서부에 있는 유학생이에요 . 성시경씨 제대 후 라디오 복...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abfb842993be20d21bfae7103addc5e9</td>\n",
       "      <td>They’ve really cut back on the content this se...</td>\n",
       "      <td>Last season there was a new pod every 3-4 days...</td>\n",
       "      <td>1</td>\n",
       "      <td>AD790CE113DCBC1</td>\n",
       "      <td>2018-04-11T13:46:47-07:00</td>\n",
       "      <td>1015394113</td>\n",
       "      <td>the-good-phight-for-philadelphia-phillies-fans</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/the-good...</td>\n",
       "      <td>The Good Phight: for Philadelphia Phillies fans</td>\n",
       "      <td>sports</td>\n",
       "      <td>they ’ ve really cut back on the content this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         podcast_id  \\\n",
       "0  b313ef8ef0d5b64290d3036ff1bbf2d2   \n",
       "1  abfb842993be20d21bfae7103addc5e9   \n",
       "\n",
       "                                               title  \\\n",
       "0                                        감성 라디오 음악도시   \n",
       "1  They’ve really cut back on the content this se...   \n",
       "\n",
       "                                             content  rating        author_id  \\\n",
       "0  미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...       5  664CCA7142E9AE8   \n",
       "1  Last season there was a new pod every 3-4 days...       1  AD790CE113DCBC1   \n",
       "\n",
       "                  created_at   itunes_id  \\\n",
       "0  2011-09-14T13:25:46-07:00   442838670   \n",
       "1  2018-04-11T13:46:47-07:00  1015394113   \n",
       "\n",
       "                                                slug  \\\n",
       "0  fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...   \n",
       "1     the-good-phight-for-philadelphia-phillies-fans   \n",
       "\n",
       "                                          itunes_url  \\\n",
       "0  https://podcasts.apple.com/us/podcast/fm-%EC%9...   \n",
       "1  https://podcasts.apple.com/us/podcast/the-good...   \n",
       "\n",
       "                                     podcast_title category  \\\n",
       "0                                      FM 음악도시(종영)    music   \n",
       "1  The Good Phight: for Philadelphia Phillies fans   sports   \n",
       "\n",
       "                                       reviews_title  \n",
       "0  감성 라디오 음악도시 미국 서부에 있는 유학생이에요 . 성시경씨 제대 후 라디오 복...  \n",
       "1  they ’ ve really cut back on the content this ...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('df_lem.csv', lineterminator='\\n', index_col = 0)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24925269",
   "metadata": {},
   "source": [
    "## Category Combination\n",
    "Merge similar categories into a new or existing category: \n",
    "- society/ religion/ government/ history/ education/ kids as “society”\n",
    "- tv/ leisure/ sports/ music/ fiction/ arts as “entertainment”\n",
    "- science/ technology/ health/ crime as “others”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cab6030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comedy        0.16038\n",
       "society       0.12890\n",
       "news          0.10412\n",
       "business      0.07566\n",
       "sports        0.07178\n",
       "arts          0.06362\n",
       "education     0.05976\n",
       "crime         0.05042\n",
       "health        0.04706\n",
       "tv            0.04354\n",
       "religion      0.04186\n",
       "leisure       0.03452\n",
       "history       0.02834\n",
       "kids          0.02448\n",
       "music         0.01782\n",
       "science       0.01640\n",
       "fiction       0.01552\n",
       "government    0.00826\n",
       "technology    0.00756\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71a342df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def replace_cat(line):\n",
    "    line = re.sub(r'\\b(society|religion|government|history|education|kids)\\b', 'society', line)\n",
    "    line = re.sub(r'\\b(tv|leisure|sports|music|fiction|arts)\\b', 'entertainment', line)\n",
    "    line = re.sub(r'\\b(science|technology|health|crime)\\b', 'others', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "df1c9f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['category'] = df['category'].apply(lambda x: replace_cat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c2e4e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "society          0.29160\n",
       "entertainment    0.24680\n",
       "comedy           0.16038\n",
       "others           0.12144\n",
       "news             0.10412\n",
       "business         0.07566\n",
       "Name: category, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c0893c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>podcast_id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>author_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>itunes_id</th>\n",
       "      <th>slug</th>\n",
       "      <th>itunes_url</th>\n",
       "      <th>podcast_title</th>\n",
       "      <th>category</th>\n",
       "      <th>reviews_title</th>\n",
       "      <th>reviews_title_pod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b313ef8ef0d5b64290d3036ff1bbf2d2</td>\n",
       "      <td>감성 라디오 음악도시</td>\n",
       "      <td>미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...</td>\n",
       "      <td>5</td>\n",
       "      <td>664CCA7142E9AE8</td>\n",
       "      <td>2011-09-14T13:25:46-07:00</td>\n",
       "      <td>442838670</td>\n",
       "      <td>fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/fm-%EC%9...</td>\n",
       "      <td>FM 음악도시(종영)</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>감성 라디오 음악도시 미국 서부에 있는 유학생이에요 . 성시경씨 제대 후 라디오 복...</td>\n",
       "      <td>감성 라디오 음악도시 미국 서부에 있는 유학생이에요 . 성시경씨 제대 후 라디오 복...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abfb842993be20d21bfae7103addc5e9</td>\n",
       "      <td>They’ve really cut back on the content this se...</td>\n",
       "      <td>Last season there was a new pod every 3-4 days...</td>\n",
       "      <td>1</td>\n",
       "      <td>AD790CE113DCBC1</td>\n",
       "      <td>2018-04-11T13:46:47-07:00</td>\n",
       "      <td>1015394113</td>\n",
       "      <td>the-good-phight-for-philadelphia-phillies-fans</td>\n",
       "      <td>https://podcasts.apple.com/us/podcast/the-good...</td>\n",
       "      <td>The Good Phight: for Philadelphia Phillies fans</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>they ’ ve really cut back on the content this ...</td>\n",
       "      <td>they ’ ve really cut back on the content this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         podcast_id  \\\n",
       "0  b313ef8ef0d5b64290d3036ff1bbf2d2   \n",
       "1  abfb842993be20d21bfae7103addc5e9   \n",
       "\n",
       "                                               title  \\\n",
       "0                                        감성 라디오 음악도시   \n",
       "1  They’ve really cut back on the content this se...   \n",
       "\n",
       "                                             content  rating        author_id  \\\n",
       "0  미국 서부에 있는 유학생이에요. 성시경씨 제대 후 라디오 복귀만 기다려오다가 6 월...       5  664CCA7142E9AE8   \n",
       "1  Last season there was a new pod every 3-4 days...       1  AD790CE113DCBC1   \n",
       "\n",
       "                  created_at   itunes_id  \\\n",
       "0  2011-09-14T13:25:46-07:00   442838670   \n",
       "1  2018-04-11T13:46:47-07:00  1015394113   \n",
       "\n",
       "                                                slug  \\\n",
       "0  fm-%EC%9D%8C%EC%95%85%EB%8F%84%EC%8B%9C-%EC%A2...   \n",
       "1     the-good-phight-for-philadelphia-phillies-fans   \n",
       "\n",
       "                                          itunes_url  \\\n",
       "0  https://podcasts.apple.com/us/podcast/fm-%EC%9...   \n",
       "1  https://podcasts.apple.com/us/podcast/the-good...   \n",
       "\n",
       "                                     podcast_title       category  \\\n",
       "0                                      FM 음악도시(종영)  entertainment   \n",
       "1  The Good Phight: for Philadelphia Phillies fans  entertainment   \n",
       "\n",
       "                                       reviews_title  \\\n",
       "0  감성 라디오 음악도시 미국 서부에 있는 유학생이에요 . 성시경씨 제대 후 라디오 복...   \n",
       "1  they ’ ve really cut back on the content this ...   \n",
       "\n",
       "                                   reviews_title_pod  \n",
       "0  감성 라디오 음악도시 미국 서부에 있는 유학생이에요 . 성시경씨 제대 후 라디오 복...  \n",
       "1  they ’ ve really cut back on the content this ...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['reviews_title_pod'] = df['reviews_title'] + ' ' + df['podcast_title']\n",
    "df['reviews_title_pod'] = df['reviews_title_pod'].astype(str)\n",
    "df['reviews_title_pod'] = df['reviews_title_pod'].apply(lambda x: x.lower())\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eef5f39",
   "metadata": {},
   "source": [
    "## Word Frequency\n",
    "Use count vectorization to find high frequency words to draw quick insights of regex target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bda4b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Countvec(words, Ngram=(1,1), token_pattern=None, min_df=1, max_df=1.0):\n",
    "    '''Create count vectorizer'''\n",
    "    vectorizer = CountVectorizer(stop_words=\"english\", ngram_range=Ngram, lowercase=True, \n",
    "                                 token_pattern=token_pattern, min_df=min_df, max_df=max_df)\n",
    "    X = vectorizer.fit_transform(words) \n",
    "    X = X.toarray()\n",
    "    print(X.shape)    \n",
    "    feature = vectorizer.get_feature_names()\n",
    "    corpus_df = pd.DataFrame(X, columns=feature)\n",
    "    return corpus_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0123c1a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 45539)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/2021/lib/python3.7/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "podcast     41705\n",
       "listen      21148\n",
       "love        17756\n",
       "like        14220\n",
       "great       13912\n",
       "episode     13436\n",
       "just        11623\n",
       "good         8906\n",
       "make         8830\n",
       "time         8276\n",
       "really       7798\n",
       "story        7398\n",
       "talk         6899\n",
       "people       5900\n",
       "host         5790\n",
       "guy          5635\n",
       "say          5579\n",
       "don          5369\n",
       "know         5288\n",
       "way          5131\n",
       "work         4868\n",
       "want         4813\n",
       "podcasts     4802\n",
       "need         4614\n",
       "best         4584\n",
       "new          4491\n",
       "life         4444\n",
       "guest        4428\n",
       "thing        4405\n",
       "think        4367\n",
       "crime        4228\n",
       "feel         4138\n",
       "look         3950\n",
       "content      3935\n",
       "come         3925\n",
       "enjoy        3816\n",
       "try          3652\n",
       "use          3593\n",
       "start        3578\n",
       "hear         3516\n",
       "year         3319\n",
       "bad          3318\n",
       "topic        3193\n",
       "real         3104\n",
       "lot          3090\n",
       "sound        2992\n",
       "fun          2981\n",
       "favorite     2956\n",
       "thank        2896\n",
       "learn        2854\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen = df['reviews_title_pod'].tolist()\n",
    "sen_vec = Countvec(words=sen, Ngram=(1,1), token_pattern=r'[a-zA-Z]{3,}')\n",
    "sen_vec.sum().sort_values(ascending=False)[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec19af",
   "metadata": {},
   "source": [
    "## Regex Cleaning\n",
    "Use Regex to remove high-frequency words based on Count Vectorization result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43ded869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_replace(line):\n",
    "    line = re.sub(r'\\b(pod(s?|casts?)|listen|love|great|episodes?|just|good|make|time|really)\\b', '', line)\n",
    "    line = re.sub(r'\\b(story|talk|people|host|guy|say|don|know|way|work|want|need|best|new|life)\\b', '', line)\n",
    "    line = re.sub(r'\\b(guest|thing|think|feel|look|come|use|year|minutes?|lot|thank|favorite)\\b', '', line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f16ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reviews_title_pod'] = df['reviews_title_pod'].apply(lambda x: word_replace(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f5caa",
   "metadata": {},
   "source": [
    "## Get Feature Space and Target Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4aec2c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"category\"]\n",
    "docs = df[\"reviews_title_pod\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54553a21",
   "metadata": {},
   "source": [
    "## Perform Label Categorical Encoding of Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d26c817",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "labels = to_categorical(encoder.fit_transform(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1dfe76",
   "metadata": {},
   "source": [
    "## Remove Stopwords Using SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "32820823",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "stopwords_removed_docs = list(\n",
    "    map(lambda doc: \" \".join([token.text for token in nlp(doc) if not token.is_stop]), docs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db57818",
   "metadata": {},
   "source": [
    "## Tokenize the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "463ba81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"UNKNOWN_TOKEN\")\n",
    "tokenizer.fit_on_texts(stopwords_removed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c342d29b",
   "metadata": {},
   "source": [
    "## Integer Encode Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "21a78d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integer_encode_documents(docs, tokenizer):\n",
    "    return tokenizer.texts_to_sequences(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe3809c",
   "metadata": {},
   "source": [
    "## Get Max Length Per Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b19f5aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_token_length_per_doc(docs: List[List[str]])-> int:\n",
    "    return max(list(map(lambda x: len(x.split()), docs)))\n",
    "\n",
    "# get the max length in terms of token length\n",
    "max_length = get_max_token_length_per_doc(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d243e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 500\n",
    "# integer encode the documents\n",
    "encoded_docs = integer_encode_documents(stopwords_removed_docs, tokenizer)\n",
    "# this is a list of lists, the numbers represent the index position of that word.\n",
    "# for instance, 33 means the 33rd word in the vocabulary\n",
    "padded_docs = pad_sequences(encoded_docs, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "97631f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 500)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_docs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04190092",
   "metadata": {},
   "source": [
    "## Split into Train/Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04d9dbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(padded_docs, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dc21fa",
   "metadata": {},
   "source": [
    "## Keras RNN/LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d7be263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toolkit\n",
    "\n",
    "VOCAB_SIZE = int(len(tokenizer.word_index) * 1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbd75e8",
   "metadata": {},
   "source": [
    "## Load in Glove Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1170ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "def load_glove_vectors():\n",
    "    embeddings_index = {}\n",
    "    with open('../datasets/glove.6B.100d.txt') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "    return embeddings_index\n",
    "\n",
    "\n",
    "embeddings_index = load_glove_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c83218",
   "metadata": {},
   "source": [
    "## Load in the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7dd8180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((VOCAB_SIZE, 100))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: # check that it is an actual word that we have embeddings for\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc666805",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7573edb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classification_rnn_model(plot=False):\n",
    "    model = Sequential() # keras model\n",
    "    model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(SimpleRNN(units=64, input_shape=(1, MAX_SEQUENCE_LENGTH)))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(6, activation='softmax')) # we changed the number of categories from 19 to 6\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model\n",
    "\n",
    "def make_lstm_classification_model(plot=False):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(VOCAB_SIZE, 100, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "    model.add(Masking(mask_value=0.0)) # masking layer, masks any words that don't have an embedding as 0s.\n",
    "    model.add(LSTM(units=32, input_shape=(1, MAX_SEQUENCE_LENGTH)))\n",
    "    model.add(Dense(16))\n",
    "    model.add(Dense(6, activation='softmax')) # we changed the number of categories from 19 to 6\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "    optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    # summarize the model\n",
    "    model.summary()\n",
    "    \n",
    "    if plot:\n",
    "        plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba40ea9",
   "metadata": {},
   "source": [
    "## Compile Model - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c681e6f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 500, 100)          5695400   \n",
      "                                                                 \n",
      " masking_2 (Masking)         (None, 500, 100)          0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 64)                10560     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                1040      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,707,102\n",
      "Trainable params: 11,702\n",
      "Non-trainable params: 5,695,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Here we try RNN model\n",
    "\n",
    "rnn = make_classification_rnn_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2e567d",
   "metadata": {},
   "source": [
    "## Fit the Model - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2eb9c719",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 147s 116ms/step - loss: 1.3194 - accuracy: 0.4975\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 148s 119ms/step - loss: 1.1205 - accuracy: 0.5863\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 150s 120ms/step - loss: 1.0288 - accuracy: 0.6267\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 143s 115ms/step - loss: 0.9637 - accuracy: 0.6552\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 144s 116ms/step - loss: 0.9126 - accuracy: 0.6759\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 146s 117ms/step - loss: 0.8694 - accuracy: 0.6945\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 150s 120ms/step - loss: 0.8350 - accuracy: 0.7081\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 174s 139ms/step - loss: 0.8063 - accuracy: 0.7175\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 153s 122ms/step - loss: 0.7825 - accuracy: 0.7282\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 138s 110ms/step - loss: 0.7603 - accuracy: 0.7370\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 135s 108ms/step - loss: 0.7429 - accuracy: 0.7431\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 136s 109ms/step - loss: 0.7233 - accuracy: 0.7495\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 134s 107ms/step - loss: 0.7094 - accuracy: 0.7543\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 133s 106ms/step - loss: 0.6963 - accuracy: 0.7600\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 150s 120ms/step - loss: 0.6851 - accuracy: 0.7642\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 145s 116ms/step - loss: 0.6715 - accuracy: 0.7679\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 143s 115ms/step - loss: 0.6627 - accuracy: 0.7714\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 145s 116ms/step - loss: 0.6522 - accuracy: 0.7750\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 163s 131ms/step - loss: 0.6421 - accuracy: 0.7790\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 147s 117ms/step - loss: 0.6336 - accuracy: 0.7831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa1601f7810>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.fit(X_train, y_train, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da16616",
   "metadata": {},
   "source": [
    "## Evaluate the Model - RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d38e2292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 16s 46ms/step - loss: 0.9514 - accuracy: 0.6979\n",
      "Accuracy: 69.790000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = rnn.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74e5c7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 14s 42ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_rnn = rnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eaf9e5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9078637554790334"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate roc-auc score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, predictions_rnn, multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1b5a806e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rnn = encoder.inverse_transform(predictions_rnn.argmax(axis=1))\n",
    "true_rnn = encoder.inverse_transform(y_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "68b2bf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2154,  384,  149,   91,   46,  126],\n",
       "       [ 273, 1823,  188,   98,   41,   53],\n",
       "       [ 152,  273, 1088,   51,    8,   34],\n",
       "       [  60,   95,   45,  790,   14,   14],\n",
       "       [ 137,  110,   49,   43,  381,   34],\n",
       "       [ 206,  137,   54,   37,   19,  743]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ['society', 'entertainment', 'comedy', 'news', 'business', 'others']\n",
    "confusion_matrix_rnn = confusion_matrix(true_rnn, pred_rnn, labels=labels)\n",
    "confusion_matrix_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15b76da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>society</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>comedy</th>\n",
       "      <th>news</th>\n",
       "      <th>business</th>\n",
       "      <th>others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>society</th>\n",
       "      <td>2154</td>\n",
       "      <td>384</td>\n",
       "      <td>149</td>\n",
       "      <td>91</td>\n",
       "      <td>46</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>273</td>\n",
       "      <td>1823</td>\n",
       "      <td>188</td>\n",
       "      <td>98</td>\n",
       "      <td>41</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>152</td>\n",
       "      <td>273</td>\n",
       "      <td>1088</td>\n",
       "      <td>51</td>\n",
       "      <td>8</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>60</td>\n",
       "      <td>95</td>\n",
       "      <td>45</td>\n",
       "      <td>790</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>137</td>\n",
       "      <td>110</td>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>381</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>206</td>\n",
       "      <td>137</td>\n",
       "      <td>54</td>\n",
       "      <td>37</td>\n",
       "      <td>19</td>\n",
       "      <td>743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               society  entertainment  comedy  news  business  others\n",
       "society           2154            384     149    91        46     126\n",
       "entertainment      273           1823     188    98        41      53\n",
       "comedy             152            273    1088    51         8      34\n",
       "news                60             95      45   790        14      14\n",
       "business           137            110      49    43       381      34\n",
       "others             206            137      54    37        19     743"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix_rnn, \n",
    "    index=['society', 'entertainment', 'comedy', 'news', 'business', 'others'], \n",
    "    columns=['society', 'entertainment', 'comedy', 'news', 'business', 'others']\n",
    ")\n",
    "cmtx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e99f00",
   "metadata": {},
   "source": [
    "## Compile Model - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "00e8f1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, 500, 100)          5695400   \n",
      "                                                                 \n",
      " masking_3 (Masking)         (None, 500, 100)          0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 32)                17024     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 6)                 102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,713,054\n",
      "Trainable params: 17,654\n",
      "Non-trainable params: 5,695,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = make_lstm_classification_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb24e7",
   "metadata": {},
   "source": [
    "## Fit the Model - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b4dadf4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 208s 163ms/step - loss: 1.2541 - accuracy: 0.5183\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 209s 168ms/step - loss: 0.9915 - accuracy: 0.6315\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 234s 188ms/step - loss: 0.8637 - accuracy: 0.6898\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 208s 166ms/step - loss: 0.7820 - accuracy: 0.7226\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 200s 160ms/step - loss: 0.7220 - accuracy: 0.7493\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 213s 170ms/step - loss: 0.6777 - accuracy: 0.7667\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 206s 164ms/step - loss: 0.6397 - accuracy: 0.7786\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 205s 164ms/step - loss: 0.6107 - accuracy: 0.7920\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 208s 166ms/step - loss: 0.5869 - accuracy: 0.8008\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 204s 163ms/step - loss: 0.5626 - accuracy: 0.8080\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 202s 161ms/step - loss: 0.5439 - accuracy: 0.8139\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 209s 167ms/step - loss: 0.5275 - accuracy: 0.8206\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 200s 160ms/step - loss: 0.5104 - accuracy: 0.8272\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 205s 164ms/step - loss: 0.4952 - accuracy: 0.8324\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 239s 191ms/step - loss: 0.4822 - accuracy: 0.8367\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 202s 162ms/step - loss: 0.4685 - accuracy: 0.8404\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 194s 155ms/step - loss: 0.4558 - accuracy: 0.8472\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 193s 154ms/step - loss: 0.4465 - accuracy: 0.8486\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 194s 155ms/step - loss: 0.4367 - accuracy: 0.8521\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 192s 154ms/step - loss: 0.4247 - accuracy: 0.8551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa11fa19190>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm.fit(X_train, y_train, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35eb4eab",
   "metadata": {},
   "source": [
    "## Evaluate the Model - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fa9609cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 23s 65ms/step - loss: 0.8882 - accuracy: 0.7463\n",
      "Accuracy: 74.629998\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = lstm.evaluate(X_test, y_test, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2df1d3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 34s 94ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_lstm = lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7903b528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9318895742414628"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate roc-auc score\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, predictions_lstm, multi_class='ovo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3adf9dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lstm = encoder.inverse_transform(predictions_lstm.argmax(axis=1))\n",
    "true_lstm = encoder.inverse_transform(y_test.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d2ef6f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.metrics._classification.confusion_matrix(y_true, y_pred, *, labels=None, sample_weight=None, normalize=None)>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "labels = ['society', 'entertainment', 'comedy', 'news', 'business', 'others']\n",
    "confusion_matrix_lstm = confusion_matrix(true_lstm, pred_lstm, labels=labels)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cd7160d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>society</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>comedy</th>\n",
       "      <th>news</th>\n",
       "      <th>business</th>\n",
       "      <th>others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>society</th>\n",
       "      <td>2333</td>\n",
       "      <td>234</td>\n",
       "      <td>154</td>\n",
       "      <td>47</td>\n",
       "      <td>60</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entertainment</th>\n",
       "      <td>295</td>\n",
       "      <td>1799</td>\n",
       "      <td>216</td>\n",
       "      <td>39</td>\n",
       "      <td>54</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>188</td>\n",
       "      <td>156</td>\n",
       "      <td>1206</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news</th>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>28</td>\n",
       "      <td>801</td>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business</th>\n",
       "      <td>125</td>\n",
       "      <td>54</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>490</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>others</th>\n",
       "      <td>175</td>\n",
       "      <td>83</td>\n",
       "      <td>55</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               society  entertainment  comedy  news  business  others\n",
       "society           2333            234     154    47        60     122\n",
       "entertainment      295           1799     216    39        54      73\n",
       "comedy             188            156    1206    10        11      35\n",
       "news                76             72      28   801        19      22\n",
       "business           125             54      36    12       490      37\n",
       "others             175             83      55    17        32     834"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmtx = pd.DataFrame(\n",
    "    confusion_matrix_lstm, \n",
    "    index=['society', 'entertainment', 'comedy', 'news', 'business', 'others'], \n",
    "    columns=['society', 'entertainment', 'comedy', 'news', 'business', 'others']\n",
    ")\n",
    "cmtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2fa5a8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 107s 68ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.5982669e-04, 1.0512244e-02, 9.5710284e-01, 3.1097555e-03,\n",
       "        1.5565929e-02, 1.2749541e-02],\n",
       "       [3.9443714e-04, 3.1592820e-03, 8.6127573e-01, 1.1532735e-01,\n",
       "        5.3606858e-03, 1.4482460e-02],\n",
       "       [6.2588160e-03, 8.1369625e-03, 2.2225364e-01, 7.3155355e-01,\n",
       "        6.3836025e-03, 2.5413450e-02],\n",
       "       ...,\n",
       "       [4.9092807e-02, 7.1147867e-02, 5.8065748e-01, 5.9593464e-03,\n",
       "        5.0274100e-02, 2.4286832e-01],\n",
       "       [1.0365872e-02, 1.5421054e-01, 4.9356303e-01, 6.8957236e-04,\n",
       "        4.8770517e-02, 2.9240042e-01],\n",
       "       [4.0157106e-02, 4.7633151e-04, 6.7028826e-01, 2.4843028e-02,\n",
       "        2.6207998e-01, 2.1553049e-03]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time consumed to scored 50,000 reviews \n",
    "lstm.predict(padded_docs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52d0848d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of society: 0.7908474576271186\n",
      "Recall of entertainment: 0.7265751211631664\n",
      "Recall of comedy: 0.75093399750934\n",
      "Recall of news: 0.7868369351669942\n",
      "Recall of business: 0.649867374005305\n",
      "Recall of others: 0.697324414715719\n"
     ]
    }
   ],
   "source": [
    "# get the recall for each categories\n",
    "for i in ['society', 'entertainment', 'comedy', 'news', 'business', 'others']:\n",
    "    print(f'Recall of {i}: {cmtx.loc[i, i]/cmtx.loc[i, :].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da3add33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision of society: 0.7308897243107769\n",
      "Precision of entertainment: 0.750208507089241\n",
      "Precision of comedy: 0.7115044247787611\n",
      "Precision of news: 0.8650107991360692\n",
      "Precision of business: 0.7357357357357357\n",
      "Precision of others: 0.742653606411398\n"
     ]
    }
   ],
   "source": [
    "# get the precision for each categories\n",
    "for i in ['society', 'entertainment', 'comedy', 'news', 'business', 'others']:\n",
    "    print(f'Precision of {i}: {cmtx.loc[i, i]/cmtx.loc[:, i].sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06679d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
